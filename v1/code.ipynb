{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需建立的 entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entities = ['procedure', 'bomProcedure', 'inventory', 'inventoryRecipt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 原始檔案目錄\n",
    "original_file_entity = './data/originaldata/original'\n",
    "\n",
    "original_file_inrelation_import = './data/originaldata/inRelation/import.ts'\n",
    "original_file_export = './data/originaldata/inRelation/export.ts'\n",
    "\n",
    "# 新的檔案目錄\n",
    "output_dir = './data/outputdata'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "處理 entity 檔案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenameeeeeee original.frontend.selectors.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.frontend.selectors.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.frontend.selectors.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.frontend.selectors.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.frontend.selectors.ts\n",
      "filenameeeeeee original.entity.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.entity.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.entity.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.entity.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.entity.ts\n",
      "filenameeeeeee original.backend.selectors.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.backend.selectors.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.backend.selectors.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.backend.selectors.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.backend.selectors.ts\n",
      "filenameeeeeee original.reducer.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.reducer.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.reducer.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.reducer.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.reducer.ts\n",
      "filenameeeeeee original.actions.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.actions.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.actions.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.actions.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.actions.ts\n",
      "filenameeeeeee original.model.ts\n",
      "生成新檔案：./data/outputdata/procedure/procedure.model.ts\n",
      "生成新檔案：./data/outputdata/bomProcedure/bomProcedure.model.ts\n",
      "生成新檔案：./data/outputdata/inventory/inventory.model.ts\n",
      "生成新檔案：./data/outputdata/inventoryRecipt/inventoryRecipt.model.ts\n"
     ]
    }
   ],
   "source": [
    "# 原始 entity 名稱和新 entity 名稱\n",
    "original_entity = 'original'\n",
    "original_entity_big = original_entity.capitalize()\n",
    "\n",
    "\n",
    "# 如果新目錄不存在，則建立它\n",
    "shutil.rmtree(output_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# 遍歷原始檔案目錄中的所有檔案\n",
    "for filename in os.listdir(original_file_entity):\n",
    "    file_path = os.path.join(original_file_entity, filename)\n",
    "    \n",
    "    # print('filenameeeeeee', filename)\n",
    "    \n",
    "\n",
    "    \n",
    "    # 只處理檔案，不處理資料夾\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "\n",
    "        \n",
    "        # 對每個新 entity 生成新檔案\n",
    "        for new_entity in new_entities:\n",
    "            new_entity_big = new_entity[0].upper() + new_entity[1:]\n",
    "            \n",
    "            \n",
    "            new_file_folder_path = os.path.join(output_dir, new_entity)\n",
    "            \n",
    "            if not os.path.exists(new_file_folder_path):\n",
    "                os.makedirs(new_file_folder_path)\n",
    "            \n",
    "            # 替換檔案內容中的 entity 名稱\n",
    "            \n",
    "            new_content = content.replace(original_entity, new_entity)\n",
    "            new_content = new_content.replace(original_entity_big, new_entity_big)\n",
    "            \n",
    "            # 替換檔案名稱中的 entity 名稱\n",
    "            new_filename = filename.replace(original_entity, new_entity)\n",
    "            new_file_path = os.path.join(new_file_folder_path, new_filename)\n",
    "            \n",
    "            # 將新內容寫入新的檔案中\n",
    "            with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "                new_file.write(new_content)\n",
    "                \n",
    "            print(f'生成新檔案：{new_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inrelation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_import = ''\n",
    "total_export = ''\n",
    "\n",
    "original_file_import = './data/originaldata/inrelation/import.ts'\n",
    "original_file_export = './data/originaldata/inrelation/export.ts'\n",
    "\n",
    "\n",
    "with open(original_file_import, 'r', encoding='utf-8') as file:\n",
    "            original_import_content = file.read()\n",
    "            \n",
    "with open(original_file_export, 'r', encoding='utf-8') as file:\n",
    "            original_export_content = file.read()\n",
    "            \n",
    "        \n",
    "for new_entity in new_entities:\n",
    "    new_entity_big = new_entity[0].upper() + new_entity[1:]\n",
    "    \n",
    "    new_import_content = original_import_content.replace(original_entity, new_entity)\n",
    "    new_import_content = new_import_content.replace(original_entity_big, new_entity_big)\n",
    "    \n",
    "    new_export_content = original_export_content.replace(original_entity, new_entity)\n",
    "    new_export_content = new_export_content.replace(original_entity_big, new_entity_big)\n",
    "\n",
    "    total_import = total_import + new_import_content\n",
    "    total_export = total_export + new_export_content\n",
    "    \n",
    "    \n",
    "\n",
    "new_file_path = os.path.join(output_dir, '1.inrelation')\n",
    "\n",
    "if not os.path.exists(new_file_path):\n",
    "    os.makedirs(new_file_path)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '1.inrelation/1.import.ts')\n",
    "\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_import)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '1.inrelation/2.export.ts')\n",
    "\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_export)\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_import = ''\n",
    "total_state = ''\n",
    "total_reducer = ''\n",
    "total_featureKey=''\n",
    "\n",
    "\n",
    "original_file_import = './data/originaldata/instore/import.ts'\n",
    "original_file_state = './data/originaldata/instore/state.ts'\n",
    "original_file_reducer = './data/originaldata/instore/reducers.ts'\n",
    "original_file_featureKey = './data/originaldata/instore/featureKeys.ts'\n",
    "\n",
    "\n",
    "with open(original_file_import, 'r', encoding='utf-8') as file:\n",
    "            original_import_content = file.read()\n",
    "with open(original_file_state, 'r', encoding='utf-8') as file:\n",
    "            original_state_content = file.read()\n",
    "with open(original_file_reducer, 'r', encoding='utf-8') as file:\n",
    "            original_reducer_content = file.read()\n",
    "with open(original_file_featureKey, 'r', encoding='utf-8') as file:\n",
    "            original_featureKey_content = file.read()\n",
    "            \n",
    "        \n",
    "for new_entity in new_entities:\n",
    "    new_entity_big = new_entity[0].upper() + new_entity[1:]\n",
    "    \n",
    "    new_import_content = original_import_content.replace(original_entity, new_entity)\n",
    "    new_import_content = new_import_content.replace(original_entity_big, new_entity_big)\n",
    "    \n",
    "    new_state_content = original_state_content.replace(original_entity, new_entity)\n",
    "    new_state_content = new_state_content.replace(original_entity_big, new_entity_big)\n",
    "    \n",
    "    new_reducer_content = original_reducer_content.replace(original_entity, new_entity)\n",
    "    new_reducer_content = new_reducer_content.replace(original_entity_big, new_entity_big)\n",
    "    \n",
    "    new_featureKey_content = original_featureKey_content.replace(original_entity, new_entity)\n",
    "    new_featureKey_content = new_featureKey_content.replace(original_entity_big, new_entity_big)\n",
    "\n",
    "    total_import = total_import + new_import_content\n",
    "    total_state = total_state + new_state_content\n",
    "    total_reducer = total_reducer + new_reducer_content\n",
    "    total_featureKey = total_featureKey + new_featureKey_content\n",
    "    \n",
    "    \n",
    "\n",
    "new_file_path = os.path.join(output_dir, '2.instore')\n",
    "\n",
    "if not os.path.exists(new_file_path):\n",
    "    os.makedirs(new_file_path)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '2.instore/1.import.ts')\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_import)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '2.instore/2.state.ts')\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_state)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '2.instore/3.reducer.ts')\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_reducer)\n",
    "    \n",
    "new_file_path = os.path.join(output_dir, '2.instore/4.featureKey.ts')\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    new_file.write(total_featureKey)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file_effect = './data/originaldata/ineffect/original.frontend.effects.ts'\n",
    "original_filename = 'original.frontend.effects.ts'\n",
    "\n",
    "with open (original_file_effect,'r',encoding='utf-8') as file:\n",
    "            original_effect_content = file.read()\n",
    "\n",
    "for new_entity in new_entities:\n",
    "    new_entity_big = new_entity[0].upper() + new_entity[1:]\n",
    "    \n",
    "    new_effect_content = original_effect_content.replace(original_entity, new_entity)\n",
    "    new_effect_content = new_effect_content.replace(original_entity_big, new_entity_big )\n",
    "    \n",
    "    new_file_path = os.path.join(output_dir, '3.effect')\n",
    "    \n",
    "    if not os.path.exists(new_file_path):\n",
    "        os.makedirs(new_file_path)\n",
    "    \n",
    "    new_filename = original_filename.replace(original_entity, new_entity)\n",
    "    new_file_path = os.path.join(new_file_path, new_entity)\n",
    "    with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "        new_file.write(new_effect_content)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
